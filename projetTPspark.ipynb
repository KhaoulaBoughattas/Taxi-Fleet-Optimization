{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e6f119-4d3b-4d80-bc06-4d7780ec90c4",
   "metadata": {},
   "source": [
    "# Projet : “Taxi Fleet Optimization – Big Data Analysis” \n",
    "### Objectif : \n",
    "Analyser des millions de courses taxi pour optimiser la flotte, prédire la demande, détecter les pics. \n",
    "Dataset Kaggle NYC Taxi Trip Dataset : \"https://www.kaggle.com/datasets/kentonnlp/nyc-taxi-trip-duration \"\n",
    "### Idées Spark : \n",
    "- Heatmap des zones les plus demandées \n",
    "- Détection des heures de rush \n",
    "- Prédiction du temps de trajet (MLlib Regression) \n",
    "- Clustering des zones (KMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab933c5c-c42c-40cd-b010-56220b855221",
   "metadata": {},
   "source": [
    "***Étape 0 : Préparer d'environnement Spark***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0db5fcc-5853-4afb-a30a-eabb73496ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Imports\n",
    "/*\n",
    "  Ici nous importons tous les packages nécessaires pour Spark SQL et DataFrame.\n",
    "  - SparkSession: point d'entrée pour Spark\n",
    "  - functions: fonctions SQL utiles (col, lit, round, udf, avg, count, etc.)\n",
    "  - types: pour les types de colonnes si besoin\n",
    "  - Window: pour les fonctions de fenêtrage (rolling, rank, etc.)\n",
    "*/\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Row}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceddfc27-1571-4005-a431-ebe19f77f648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@74d9532c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@74d9532c"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder()\n",
    "  .appName(\"NYC Taxi Deep EDA\")\n",
    "  .config(\"spark.master\", \"local[*]\")\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "spark.sparkContext.setLogLevel(\"WARN\") // Réduction du niveau de logs pour ne voir que WARN ou plus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42d43c-5e77-48cd-8a19-e80a1fe57702",
   "metadata": {},
   "source": [
    "***Interprétation :*** Cette cellule prépare l'environnement Spark et importe tout ce qui est nécessaire pour manipuler les données. Le local[*] permet d'utiliser tous les cœurs CPU disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0476bc7-e3ca-4e65-93a9-2ea4cc925087",
   "metadata": {},
   "source": [
    "***Étape 1 : Ingestion des données***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a974a6f-3278-4262-a77b-a8875da6b95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputCsv = data/NYC.csv\n",
       "outputsDir = outputs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "outputs"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//CONFIG\n",
    "val inputCsv = \"data/NYC.csv\"\n",
    "val outputsDir = \"outputs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56ed19-f2fb-4385-a2d0-ffdde15295c5",
   "metadata": {},
   "source": [
    "***Interprétation :*** Tous les outputs (analyses, heatmaps, pivot tables) seront écrits dans ce dossier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a89be18-8548-4746-a209-b43086347d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading CSV...\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- trip_duration: integer (nullable = true)\n",
      "\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "|id       |vendor_id|pickup_datetime    |dropoff_datetime   |passenger_count|pickup_longitude  |pickup_latitude   |dropoff_longitude |dropoff_latitude  |store_and_fwd_flag|trip_duration|\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "|id2875421|2        |2016-03-14 17:24:55|2016-03-14 17:32:30|1              |-73.9821548461914 |40.76793670654297 |-73.96463012695312|40.765602111816406|N                 |455          |\n",
      "|id2377394|1        |2016-06-12 00:43:35|2016-06-12 00:54:38|1              |-73.98041534423828|40.738563537597656|-73.99948120117188|40.73115158081055 |N                 |663          |\n",
      "|id3858529|2        |2016-01-19 11:35:24|2016-01-19 12:10:48|1              |-73.9790267944336 |40.763938903808594|-74.00533294677734|40.710086822509766|N                 |2124         |\n",
      "|id3504673|2        |2016-04-06 19:32:31|2016-04-06 19:39:40|1              |-74.01004028320312|40.719970703125   |-74.01226806640625|40.70671844482422 |N                 |429          |\n",
      "|id2181028|2        |2016-03-26 13:30:55|2016-03-26 13:38:10|1              |-73.97305297851562|40.793209075927734|-73.9729232788086 |40.78252029418945 |N                 |435          |\n",
      "+---------+---------+-------------------+-------------------+---------------+------------------+------------------+------------------+------------------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total rows (raw): 1458644\n",
      "  id -> 1458644 distinct\n",
      "  vendor_id -> 2 distinct\n",
      "  pickup_datetime -> 1380222 distinct\n",
      "  dropoff_datetime -> 1380377 distinct\n",
      "  passenger_count -> 10 distinct\n",
      "  pickup_longitude -> 23047 distinct\n",
      "  pickup_latitude -> 45245 distinct\n",
      "  dropoff_longitude -> 33821 distinct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfRaw = [id: string, vendor_id: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 9 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Charger le dataset CSV\n",
    "println(\"==> Loading CSV...\")\n",
    "\n",
    "val dfRaw = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(inputCsv)\n",
    "\n",
    "dfRaw.printSchema() //inferSchema permet de détecter automatiquement le type des colonnes\n",
    "dfRaw.show(5, truncate = false)\n",
    "\n",
    "println(s\"Total rows (raw): ${dfRaw.count()}\") // Nombre total de lignes\n",
    "\n",
    "// Vérification rapide des valeurs distinctes sur les premières colonnes\n",
    "dfRaw.columns.take(8).foreach { c =>\n",
    "  val d = dfRaw.select(col(c)).distinct().count()\n",
    "  println(s\"  $c -> $d distinct\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c676b9a-0e60-4e2f-9d9d-748b36e124a9",
   "metadata": {},
   "source": [
    "***Interprétation :****\n",
    "\n",
    "- Les types ont été correctement inférés par Spark (ex: vendor_id est un int, les coordonnées sont des double).\n",
    "\n",
    "- Les dates sont encore en string : il faudra les convertir en Timestamp pour des analyses temporelles.\n",
    "\n",
    "- Les colonnes id et store_and_fwd_flag sont des chaînes (string).\n",
    "\n",
    "- Il y a 1,458,644 trajets dans le dataset : un dataset très volumineux, parfait pour Spark et l’analyse Big Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbfede-acab-4b6c-a11e-7bfbebb3106b",
   "metadata": {},
   "source": [
    "***Aperçu des données (5 premières lignes)***\n",
    "\n",
    "Quelques observations :\n",
    "\n",
    "- id semble unique pour chaque course.\n",
    "\n",
    "- vendor_id a des valeurs 1 ou 2 (il s’agit probablement des compagnies de taxi).\n",
    "\n",
    "- pickup_datetime et dropoff_datetime sont sous format YYYY-MM-DD HH:MM:SS.\n",
    "\n",
    "- Les coordonnées (pickup_longitude/latitude, dropoff_longitude/latitude) sont réalistes pour NYC (longitude ~ -73 / latitude ~ 40).\n",
    "\n",
    "- trip_duration est en secondes, et varie beaucoup (ex: 429 sec ≈ 7 min, 2124 sec ≈ 35 min)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a7df0-edb7-4604-8d2b-80eadcda2fef",
   "metadata": {},
   "source": [
    "***Valeurs distinctes par colonne :***\n",
    "| Colonne             | Distincts  | Interprétation                                                                                            |\n",
    "| ------------------- | ---------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| `id`                | 1,458,644  | Chaque course a un identifiant unique, pas de doublons.                                                   |\n",
    "| `vendor_id`         | 2          | Deux fournisseurs/compagnies de taxi seulement.                                                           |\n",
    "| `pickup_datetime`   | 1,380,222  | La majorité des dates sont uniques, mais certaines heures/dates se répètent (ex: trajets au même moment). |\n",
    "| `dropoff_datetime`  | 1,380,377  | Très proche de `pickup_datetime`, donc la plupart des courses ont des durées uniques.                     |\n",
    "| `passenger_count`   | 10         | Seules 10 valeurs différentes : prob. 1 à 6 passagers + valeurs aberrantes.                               |\n",
    "| `pickup_longitude`  | 23,047     | Beaucoup de coordonnées uniques : la majorité des trajets commencent à des endroits différents.           |\n",
    "| `pickup_latitude`   | 45,245     | Idem longitude. La différence longitude/latitude montre une forte densité spatiale (ex: Manhattan).       |\n",
    "| `dropoff_longitude` | 33,821     | Plus de variation que pickup_longitude → certains trajets finissent à des endroits plus variés.           |\n",
    "| `dropoff_latitude`  | non listée | Probablement similaire à dropoff_longitude.                                                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49dab5-ba39-4054-a74a-61cebe99e21f",
   "metadata": {},
   "source": [
    "***Observations importantes :***\n",
    "\n",
    "Les trajets sont très dispersés géographiquement, surtout pour les dropoffs.\n",
    "\n",
    "passenger_count est limité à 10 valeurs distinctes, donc on peut faire une analyse de distribution simple.\n",
    "\n",
    "La majorité des identifiants (id) sont uniques, donc aucune duplication immédiate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06463-e8a3-4d53-8b38-b8191cf474ca",
   "metadata": {},
   "source": [
    "***Étape 2 : Prétraitement et Features Engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0ed65d-00e1-4956-921d-057923284093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après nettoyage: 1449843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfNonNull = [id: string, vendor_id: int ... 9 more fields]\n",
       "dfFiltered = [id: string, vendor_id: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 9 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Nettoyage basique des données\n",
    "/*\n",
    "  1) Suppression des lignes contenant des valeurs nulles\n",
    "  2) Filtrage des trip_duration improbables (<1 min ou >27h)\n",
    "  3) Filtrage des passagers invalides (0 ou >6)\n",
    "*/\n",
    "\n",
    "//Suppression des lignes avec valeurs nulles\n",
    "val dfNonNull = dfRaw.na.drop()\n",
    "/*Toute ligne contenant au moins une valeur manquante est supprimée.\n",
    "Cela garantit que toutes les colonnes seront non nulles pour les analyses suivantes.*/\n",
    "\n",
    "val dfFiltered = dfNonNull\n",
    "  .filter($\"trip_duration\".isNotNull && $\"trip_duration\" > 60 && $\"trip_duration\" < 100000)//Filtrage sur trip_duration\n",
    "/*Les trajets de moins de 1 minute (60 secondes) sont considérés comme des erreurs ou des trajets très courts improbables.\n",
    "Les trajets de plus de 100 000 secondes (~27h) sont également supprimés, car ce sont probablement des anomalies ou des erreurs de saisie.*/\n",
    "\n",
    "  .filter($\"passenger_count\".isNotNull && $\"passenger_count\" > 0 && $\"passenger_count\" < 7) //Filtrage sur passenger_count\n",
    "/*Les trajets avec 0 passager sont invalides.\n",
    "\n",
    "Les trajets avec plus de 6 passagers sont rares pour un taxi standard, donc considérés comme aberrants.*/\n",
    "println(s\"Nombre de lignes après nettoyage: ${dfFiltered.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002269d-e0d8-475c-8a66-06ec27952e50",
   "metadata": {},
   "source": [
    "***Interprétation :***\n",
    "\n",
    "- Le dataset initial avait 1,458,644 lignes.\n",
    "\n",
    "- Après suppression des valeurs nulles et filtrages, il reste 1,449,843 lignes.\n",
    "\n",
    "- Donc environ 8,801 lignes ont été supprimées (~0,6 % du dataset).\n",
    "\n",
    ">Cela signifie que la grande majorité des données est valide et exploitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b10cc4-11dd-4091-9519-bcf5c4be6c45",
   "metadata": {},
   "source": [
    "***Points clés sur la qualité des données***\n",
    "\n",
    "- Les valeurs nulles sont rares → le dataset est assez propre.\n",
    "\n",
    "- Les anomalies sur trip_duration ou passenger_count sont très limitées.\n",
    "\n",
    "- Après nettoyage, le dataset est prêt pour :\n",
    "\n",
    "    - Analyse descriptive (durée moyenne, distribution des passagers, fréquence des trajets par heure/jour).\n",
    "\n",
    "    - Analyse spatiale (coordonnées de pickup/dropoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dc43a0-a182-4a42-b0db-85d986dc98d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+----------------+------------+--------------+\n",
      "|pickup_ts|dropoff_ts|pickup_hour|pickup_dayofweek|pickup_month|pickup_weekday|\n",
      "+---------+----------+-----------+----------------+------------+--------------+\n",
      "|     null|      null|       null|            null|        null|             0|\n",
      "|     null|      null|       null|            null|        null|             0|\n",
      "|     null|      null|       null|            null|        null|             0|\n",
      "|     null|      null|       null|            null|        null|             0|\n",
      "|     null|      null|       null|            null|        null|             0|\n",
      "+---------+----------+-----------+----------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfTime = [id: string, vendor_id: int ... 15 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 15 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Parsing timestamps et features temporelles\n",
    "/*\n",
    "  Conversion des colonnes pickup_datetime et dropoff_datetime en type Timestamp\n",
    "  - Création de nouvelles colonnes temporelles utiles pour l'analyse:\n",
    "    - pickup_hour : heure de la course\n",
    "    - pickup_dayofweek : jour de la semaine\n",
    "    - pickup_month : mois\n",
    "    - pickup_weekday : indicateur 1=semaine, 0=weekend\n",
    "*/\n",
    "\n",
    "val dfTime = dfFiltered\n",
    "    //convertir les colonnes pickup_datetime et dropoff_datetime en Timestamp\n",
    "  .withColumn(\"pickup_ts\", to_timestamp($\"pickup_datetime\",\"dd/MM/yyyy HH:mm\"))\n",
    "  .withColumn(\"dropoff_ts\", to_timestamp($\"dropoff_datetime\",\"dd/MM/yyyy HH:mm\"))\n",
    "    //création des features temporelles utiles pour l’analyse :\n",
    "  .withColumn(\"pickup_hour\", hour($\"pickup_ts\")) //pickup_hour : heure du jour (0–23)\n",
    "  .withColumn(\"pickup_dayofweek\", date_format($\"pickup_ts\", \"E\"))  // pickup_dayofweek : jour de la semaine (Mon, Tue…)\n",
    "  .withColumn(\"pickup_month\", month($\"pickup_ts\")) //pickup_month : mois (1–12)\n",
    "  //pickup_weekday : 1 si jour de semaine, 0 si weekend\n",
    "  .withColumn(\"pickup_weekday\",\n",
    "      when(dayofweek($\"pickup_ts\").between(2,6), 1).otherwise(0)\n",
    "  )\n",
    "\n",
    "\n",
    "// Vérification\n",
    "dfTime.select(\"pickup_ts\",\"dropoff_ts\",\"pickup_hour\",\"pickup_dayofweek\",\"pickup_month\",\"pickup_weekday\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92436209-4a8c-4be1-a9de-28ff17171a13",
   "metadata": {},
   "source": [
    "***Observation :*** toutes les valeurs sont null, sauf pickup_weekday qui par défaut prend 0 (weekend)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6f4d4-0a43-447e-a802-18c8a131ffa8",
   "metadata": {},
   "source": [
    "***Pourquoi toutes les dates sont nulles***\n",
    "\n",
    "La cause est le format de date fourni à to_timestamp :\n",
    "\n",
    "to_timestamp($\"pickup_datetime\",\"dd/MM/yyyy HH:mm\")\n",
    "\n",
    "\n",
    "- La dataset montre des dates comme : \"2016-03-14 17:24:55\"\n",
    "\n",
    "- Le format \"dd/MM/yyyy HH:mm\" ne correspond pas :\n",
    "\n",
    "    - Les dates ont le format yyyy-MM-dd HH:mm:ss\n",
    "\n",
    "    - Le format actuel attend jour/mois/année heure:minute et ignore les secondes, donc Spark ne peut pas parser → retourne null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93246cfe-5ea0-41f4-a434-7db0bfe011e8",
   "metadata": {},
   "source": [
    "***Comment corriger***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869516de-00e9-4224-87b3-3d3b218e72de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------+----------------+------------+--------------+\n",
      "|          pickup_ts|         dropoff_ts|pickup_hour|pickup_dayofweek|pickup_month|pickup_weekday|\n",
      "+-------------------+-------------------+-----------+----------------+------------+--------------+\n",
      "|2016-03-14 17:24:55|2016-03-14 17:32:30|         17|             Mon|           3|             1|\n",
      "|2016-06-12 00:43:35|2016-06-12 00:54:38|          0|             Sun|           6|             0|\n",
      "|2016-01-19 11:35:24|2016-01-19 12:10:48|         11|             Tue|           1|             1|\n",
      "|2016-04-06 19:32:31|2016-04-06 19:39:40|         19|             Wed|           4|             1|\n",
      "|2016-03-26 13:30:55|2016-03-26 13:38:10|         13|             Sat|           3|             0|\n",
      "+-------------------+-------------------+-----------+----------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfTime = [id: string, vendor_id: int ... 15 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 15 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfTime = dfFiltered\n",
    "  .withColumn(\"pickup_ts\", to_timestamp($\"pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "  .withColumn(\"dropoff_ts\", to_timestamp($\"dropoff_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "  .withColumn(\"pickup_hour\", hour($\"pickup_ts\"))\n",
    "  .withColumn(\"pickup_dayofweek\", date_format($\"pickup_ts\", \"E\"))\n",
    "  .withColumn(\"pickup_month\", month($\"pickup_ts\"))\n",
    "  .withColumn(\"pickup_weekday\", when(dayofweek($\"pickup_ts\").between(2,6), 1).otherwise(0))\n",
    "// Vérification\n",
    "dfTime.select(\"pickup_ts\",\"dropoff_ts\",\"pickup_hour\",\"pickup_dayofweek\",\"pickup_month\",\"pickup_weekday\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc446e-f7e3-41cf-bc57-0081597b9762",
   "metadata": {},
   "source": [
    "- Maintenant Spark pourra parser correctement les dates.\n",
    "\n",
    "- Les nouvelles colonnes pickup_hour, pickup_dayofweek, pickup_month, pickup_weekday auront des valeurs correctes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e498df-b180-46e5-a01a-fe2316349b7f",
   "metadata": {},
   "source": [
    "- Les colonnes pickup_ts et dropoff_ts sont maintenant des Timestamps, donc exploitables pour des calculs temporels.\n",
    "\n",
    "- On peut maintenant calculer des durées, grouper par heure, jour ou mois, et effectuer des analyses temporelles fiables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d4405-a8fc-417f-b798-4d356d249d2a",
   "metadata": {},
   "source": [
    "***Features temporelles créées***\n",
    "| Colonne            | Exemple | Interprétation                                                                                 |\n",
    "| ------------------ | ------- | ---------------------------------------------------------------------------------------------- |\n",
    "| `pickup_hour`      | 17      | L’heure de départ de la course (0–23). Utile pour analyser la répartition horaire des trajets. |\n",
    "| `pickup_dayofweek` | Mon     | Jour de la semaine au format abrégé. Permet de voir les patterns hebdomadaires.                |\n",
    "| `pickup_month`     | 3       | Mois du trajet. Permet d’analyser la saisonnalité.                                             |\n",
    "| `pickup_weekday`   | 1       | 1 si jour de semaine, 0 si weekend. Utile pour différencier activité travail vs loisirs.       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f7a337-8a0c-40bd-b14e-3490b5999c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+------------------+\n",
      "|   pickup_latitude|  pickup_longitude|  dropoff_latitude| dropoff_longitude|       distance_km|\n",
      "+------------------+------------------+------------------+------------------+------------------+\n",
      "| 40.76793670654297| -73.9821548461914|40.765602111816406|-73.96463012695312|1.4985207796474773|\n",
      "|40.738563537597656|-73.98041534423828| 40.73115158081055|-73.99948120117188|1.8055071687958235|\n",
      "|40.763938903808594| -73.9790267944336|40.710086822509766|-74.00533294677734|  6.38509849525294|\n",
      "|   40.719970703125|-74.01004028320312| 40.70671844482422|-74.01226806640625| 1.485498422771006|\n",
      "|40.793209075927734|-73.97305297851562| 40.78252029418945| -73.9729232788086| 1.188588459334221|\n",
      "+------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "haversine = SparkUserDefinedFunction($Lambda$4586/0x00000008417c7840@5066e376,DoubleType,List(Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double])),None,false,true)\n",
       "dfDist = [id: string, vendor_id: int ... 16 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 16 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calcul de la distance avec Haversine\n",
    "/*\n",
    "  Création d'une UDF pour calculer la distance \"à vol d'oiseau\" en km entre\n",
    "  le point de départ et d'arrivée. La formule Haversine est précise pour la sphère terrestre.\n",
    "*/\n",
    "\n",
    "val haversine = udf((lat1: Double, lon1: Double, lat2: Double, lon2: Double) => {\n",
    "  val R = 6371.0  // rayon de la Terre en km\n",
    "  val dLat = math.toRadians(lat2 - lat1)\n",
    "  val dLon = math.toRadians(lon2 - lon1)\n",
    "  val a = math.pow(math.sin(dLat/2),2) +\n",
    "          math.cos(math.toRadians(lat1)) *\n",
    "          math.cos(math.toRadians(lat2)) *\n",
    "          math.pow(math.sin(dLon/2),2)\n",
    "  val c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "  R * c\n",
    "})\n",
    "\n",
    "// Application de la fonction\n",
    "val dfDist = dfTime.withColumn(\"distance_km\", haversine(\n",
    "  $\"pickup_latitude\", $\"pickup_longitude\", $\"dropoff_latitude\", $\"dropoff_longitude\"\n",
    "))\n",
    "\n",
    "dfDist.select(\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\",\"distance_km\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedbfa0-e392-492b-85f5-46ff70a74b46",
   "metadata": {},
   "source": [
    "***Objectif du code***\n",
    "\n",
    "- Calculer la distance “à vol d’oiseau” entre le point de départ (pickup) et d’arrivée (dropoff) pour chaque course.\n",
    "\n",
    "- Utilisation de la formule Haversine, qui tient compte de la sphère terrestre (plus précise que la distance euclidienne simple).\n",
    "\n",
    "- Résultat en kilomètres dans une nouvelle colonne distance_km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c41ad-003b-4ae7-a94b-ae01cd6c5e23",
   "metadata": {},
   "source": [
    "***Aperçu des résultats***\n",
    "Exemple des 5 premières lignes :\n",
    "| pickup_lat | pickup_lon | dropoff_lat | dropoff_lon | distance_km |\n",
    "| ---------- | ---------- | ----------- | ----------- | ----------- |\n",
    "| 40.768     | -73.982    | 40.766      | -73.965     | 1.50        |\n",
    "| 40.739     | -73.980    | 40.731      | -73.999     | 1.81        |\n",
    "| 40.764     | -73.979    | 40.710      | -74.005     | 6.39        |\n",
    "| 40.720     | -74.010    | 40.707      | -74.012     | 1.49        |\n",
    "| 40.793     | -73.973    | 40.783      | -73.973     | 1.19        |\n",
    "\n",
    "***Interprétation :***\n",
    "\n",
    "- Les distances semblent réalistes pour des trajets à NYC :\n",
    "\n",
    "    - Courtes courses → ~1–2 km\n",
    "\n",
    "    - Courses plus longues → 6 km et plus\n",
    "\n",
    "- On peut maintenant analyser :\n",
    "\n",
    "    - Distribution des distances\n",
    "\n",
    "    - Relation entre distance_km et trip_duration (vitesse moyenne)\n",
    "\n",
    "    - Détection de trajets aberrants (distance très grande ou nulle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efaebf9-1230-45bf-b93f-a96d2d6c7591",
   "metadata": {},
   "source": [
    "***Utilité de cette feature***\n",
    "\n",
    "distance_km est essentielle pour :\n",
    "\n",
    "- Études de performance des trajets (temps vs distance)\n",
    "\n",
    "- Détection des anomalies\n",
    "\n",
    "- Visualisations géospatiales et heatmaps\n",
    "\n",
    "- Éventuelles modélisations prédictives (ex: prédire trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec8a380-e8c7-4699-821f-65234a7ec74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfSpeed = [id: string, vendor_id: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+------------------+------------------+\n",
      "|trip_duration|         trip_min|       distance_km|        speed_kmph|\n",
      "+-------------+-----------------+------------------+------------------+\n",
      "|          455|7.583333333333333|1.4985207796474773| 11.85642814666136|\n",
      "|          663|            11.05|1.8055071687958235| 9.803658835090443|\n",
      "|         2124|             35.4|  6.38509849525294|10.822200839411764|\n",
      "|          429|             7.15| 1.485498422771006|12.465721030246204|\n",
      "|          435|             7.25| 1.188588459334221| 9.836594146214244|\n",
      "+-------------+-----------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 18 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Trip duration en minutes et vitesse\n",
    "/*\n",
    "  - trip_min : conversion de la durée en secondes vers minutes\n",
    "  - speed_kmph : calcul de la vitesse moyenne en km/h\n",
    "  Cette feature est utile pour détecter les courses anormales ou trop lentes/rapides.\n",
    "*/\n",
    "\n",
    "val dfSpeed = dfDist.withColumn(\"trip_min\", $\"trip_duration\"/60.0)\n",
    "  .withColumn(\"speed_kmph\", $\"distance_km\"/($\"trip_min\"/60.0))\n",
    "\n",
    "dfSpeed.select(\"trip_duration\",\"trip_min\",\"distance_km\",\"speed_kmph\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bc726-7329-423e-b58f-431b1f101bdb",
   "metadata": {},
   "source": [
    "***Objectif du code:***\n",
    "\n",
    "- trip_min : conversion de la durée du trajet de secondes → minutes, plus lisible pour interprétation.\n",
    "\n",
    "- speed_kmph : calcul de la vitesse moyenne du trajet en km/h.\n",
    "\n",
    "- Utile pour détecter des trajets anormalement rapides ou lents, ou des erreurs de saisie dans les données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf88338-3ea9-4018-855a-d2280f03de21",
   "metadata": {},
   "source": [
    "***Interprétation :***\n",
    "\n",
    "- La vitesse moyenne des trajets est raisonnable pour NYC, autour de 10–12 km/h, ce qui correspond à la circulation urbaine.\n",
    "\n",
    "- Même pour des trajets plus longs (35 min / 6.39 km), la vitesse moyenne reste cohérente (~10.8 km/h).\n",
    "\n",
    "- Les valeurs permettent de détecter les anomalies :\n",
    "\n",
    "    - Vitesse trop faible (<5 km/h) → peut indiquer arrêt prolongé ou erreur dans les données.\n",
    "\n",
    "    - Vitesse trop élevée (>100 km/h) → probablement une erreur de saisie (ex: coordonnée ou durée)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0ab0e-0bd5-4fe3-840f-f77fba3a2012",
   "metadata": {},
   "source": [
    "***Utilité de ces nouvelles features***\n",
    "\n",
    "- trip_min : plus intuitive que trip_duration pour la lecture et les analyses statistiques.\n",
    "\n",
    "- speed_kmph :\n",
    "\n",
    "    - Permet de filtrer les courses anormales.\n",
    "\n",
    "    - Peut être utilisée comme feature pour un modèle prédictif de durée.\n",
    "\n",
    "    - Utile pour analyses urbaines (identifier zones de trafic lent/rapide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cea786b-8b98-48cf-ab2f-c64574b9e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|pickup_hour|count|\n",
      "+-----------+-----+\n",
      "|          0|52840|\n",
      "|          1|38290|\n",
      "|          2|27714|\n",
      "|          3|20684|\n",
      "|          4|15558|\n",
      "|          5|14789|\n",
      "|          6|32962|\n",
      "|          7|55268|\n",
      "|          8|66732|\n",
      "|          9|67320|\n",
      "|         10|65100|\n",
      "|         11|68103|\n",
      "|         12|71466|\n",
      "|         13|71096|\n",
      "|         14|73831|\n",
      "|         15|71366|\n",
      "|         16|63863|\n",
      "|         17|76015|\n",
      "|         18|90152|\n",
      "|         19|89858|\n",
      "|         20|83653|\n",
      "|         21|83721|\n",
      "|         22|80073|\n",
      "|         23|69389|\n",
      "+-----------+-----+\n",
      "\n",
      "+----------------+------+\n",
      "|pickup_dayofweek| count|\n",
      "+----------------+------+\n",
      "|             Fri|222192|\n",
      "|             Sat|219567|\n",
      "|             Thu|217232|\n",
      "|             Wed|209004|\n",
      "|             Tue|201587|\n",
      "|             Sun|194005|\n",
      "|             Mon|186256|\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tripsByHour = [pickup_hour: int, count: bigint]\n",
       "tripsByWeekday = [pickup_dayofweek: string, count: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[pickup_dayofweek: string, count: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Agrégations temporelles\n",
    "/*\n",
    "  Analyse du nombre de courses par heure et par jour de la semaine\n",
    "  - tripsByHour : utile pour détecter les heures de pointe\n",
    "  - tripsByWeekday : utile pour détecter les jours les plus chargés\n",
    "*/\n",
    "\n",
    "val tripsByHour = dfSpeed.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n",
    "tripsByHour.show(24)\n",
    "\n",
    "val tripsByWeekday = dfSpeed.groupBy(\"pickup_dayofweek\").count().orderBy(desc(\"count\"))\n",
    "tripsByWeekday.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1953d-64e7-40c1-95b2-affcbd47789b",
   "metadata": {},
   "source": [
    "***Courses par heure (tripsByHour)***\n",
    "\n",
    "- Les trajets sont moins nombreux la nuit (minuit–5h : 15 558 à 52 840 trajets).\n",
    "\n",
    "- La fréquentation augmente à partir de 6h, avec des pics visibles :\n",
    "\n",
    "    - 8h–10h → heure de pointe du matin (commuters).\n",
    "\n",
    "    - 17h–19h → pic l’après-midi/soir (retours du travail).\n",
    "\n",
    "- Le maximum est à 18h (90 152 trajets) → fort trafic urbain.\n",
    "\n",
    "***Courses par jour de la semaine (tripsByWeekday)***\n",
    "\n",
    "- Vendredi et samedi sont les jours les plus chargés : 222 192 et 219 567 trajets → activités sociales et travail.\n",
    "\n",
    "- Lundi et dimanche sont les moins chargés : 186 256 et 194 005 trajets.\n",
    "\n",
    "- Le dataset reflète le pattern urbain classique : plus de trajets en fin de semaine et pendant les heures de pointe.\n",
    "\n",
    "\n",
    "***En résumé :*** Les données montrent une activité élevée aux heures de pointe et une répartition hebdomadaire typique, utile pour analyses de trafic ou planification de services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e42da8-1a47-4c38-b886-d2f01eafeef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfHeat = [id: string, vendor_id: int ... 20 more fields]\n",
       "heatmap = [pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----+\n",
      "|pickup_lat_bin_0_01|pickup_lon_bin_0_01|count|\n",
      "+-------------------+-------------------+-----+\n",
      "|              40.76|             -73.97|89872|\n",
      "|              40.75|             -73.99|89744|\n",
      "|              40.76|             -73.98|77421|\n",
      "|              40.75|             -73.98|72329|\n",
      "|              40.74|             -73.99|65562|\n",
      "|              40.76|             -73.99|65369|\n",
      "|              40.77|             -73.96|51198|\n",
      "|              40.73|             -73.99|50993|\n",
      "|              40.77|             -73.98|47558|\n",
      "|              40.73|              -74.0|44185|\n",
      "|              40.74|              -74.0|43723|\n",
      "|              40.74|             -73.98|41274|\n",
      "|              40.78|             -73.96|38929|\n",
      "|              40.78|             -73.95|37617|\n",
      "|              40.78|             -73.98|35930|\n",
      "|              40.72|             -73.99|34007|\n",
      "|              40.75|             -73.97|32117|\n",
      "|              40.77|             -73.95|27824|\n",
      "|              40.72|              -74.0|27651|\n",
      "|              40.76|             -73.96|25490|\n",
      "+-------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 1 more field]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Création de bins pour heatmap\n",
    "/*\n",
    "  Pour visualiser les zones les plus demandées, nous arrondissons les coordonnées\n",
    "  afin de créer des \"bins\" (zones) de latitude/longitude.\n",
    "*/\n",
    "\n",
    "val dfHeat = dfSpeed\n",
    "  .withColumn(\"pickup_lat_bin_0_01\", round($\"pickup_latitude\", 2))\n",
    "  .withColumn(\"pickup_lon_bin_0_01\", round($\"pickup_longitude\", 2))\n",
    "\n",
    "val heatmap = dfHeat.groupBy(\"pickup_lat_bin_0_01\",\"pickup_lon_bin_0_01\").count().orderBy(desc(\"count\"))\n",
    "heatmap.show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624fd67-4f2a-4deb-a745-c575b2e4eceb",
   "metadata": {},
   "source": [
    "**Interprétation**:\n",
    "Les premières lignes montrent des bins autour de :\n",
    "\n",
    "Latitude ≈ 40.75 – 40.78\n",
    "\n",
    "Longitude ≈ -73.95 – -74.00\n",
    "\n",
    "=> Ces coordonnées correspondent à des zones très centrales de Manhattan, notamment :\n",
    "\n",
    "Midtown Manhattan\n",
    "\n",
    "Times Square\n",
    "\n",
    "Grand Central\n",
    "\n",
    "Zones de bureaux, tourisme et transports\n",
    "\n",
    "Par exemple :\n",
    "\n",
    "La zone (40.76, -73.97) compte ~89 000 trajets, ce qui indique une très forte demande.\n",
    "\n",
    "Plusieurs bins adjacents ont des volumes similaires, ce qui confirme une concentration spatiale importante des pickups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf33d39-1caf-4a51-9361-2f78da5228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Cell 9: Export CSV pour visualisation\n",
    "/*\n",
    "  On exporte les résultats d'analyse pour créer des visualisations externes\n",
    "  (par exemple dans Excel, Tableau, PowerBI ou folium/kepler pour cartes)\n",
    "*/\n",
    "\n",
    "tripsByHour.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/trips_by_hour\")\n",
    "tripsByWeekday.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/trips_by_weekday\")\n",
    "heatmap.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/heatmap_bins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e78c98-d346-4188-8042-9268c91b9b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|pickup_lat_bin_0_01|pickup_lon_bin_0_01|  0|  1|  2|  3|  4|  5|  6|  7|  8|  9| 10| 11| 12| 13| 14| 15| 16| 17| 18| 19| 20| 21| 22| 23|\n",
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|              40.65|             -73.96| 14| 10|  6|  4|  8|  5|  7|  8|  2|  2|  5|  0|  1|  1|  0|  2|  1|  3|  2|  0|  3|  4|  5| 10|\n",
      "|              40.81|             -73.99|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|\n",
      "|              40.59|             -73.95|  0|  0|  0|  0|  2|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|              40.68|             -73.82|  1|  1|  0|  0|  0|  0|  0|  1|  2|  2|  1|  0|  1|  0|  0|  0|  0|  1|  2|  0|  0|  3|  2|  3|\n",
      "|              40.81|             -74.08|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "demandPerZoneHour = [pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 2 more fields]\n",
       "pivotZone = [pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 24 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 24 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Cell 10: Pivot zone x heure pour clustering\n",
    "/*\n",
    "  Création d'un tableau pivot zone (lat/lon bin) x heure\n",
    "  - chaque cellule contient le nombre de courses\n",
    "  - préparation pour clustering ou analyse de la demande par zone/heure\n",
    "*/\n",
    "\n",
    "val demandPerZoneHour = dfHeat.groupBy(\"pickup_lat_bin_0_01\",\"pickup_lon_bin_0_01\",\"pickup_hour\")\n",
    "  .agg(count(lit(1)).alias(\"n_trips\"))\n",
    "\n",
    "val pivotZone = demandPerZoneHour.groupBy(\"pickup_lat_bin_0_01\",\"pickup_lon_bin_0_01\")\n",
    "  .pivot(\"pickup_hour\")\n",
    "  .agg(first(\"n_trips\"))\n",
    "  .na.fill(0)\n",
    "\n",
    "pivotZone.show(5)\n",
    "pivotZone.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/pivot_zone_hourly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c90286-b700-47d2-b0e9-e17d7f95e622",
   "metadata": {},
   "source": [
    "**Interprétation** :\n",
    "\n",
    "La seconde partie crée un tableau pivot où :\n",
    "\n",
    "- chaque ligne représente une zone géographique (bin latitude/longitude),\n",
    "\n",
    "- chaque colonne correspond à une heure de la journée (0 à 23),\n",
    "\n",
    "- chaque valeur indique le nombre de courses dans cette zone à cette heure.\n",
    "\n",
    "Les valeurs manquantes sont remplacées par 0, ce qui garantit un tableau complet et exploitable pour des analyses avancées.\n",
    "\n",
    "=>Lecture des résultats\n",
    "\n",
    "Les résultats montrent que :\n",
    "\n",
    "- certaines zones ont une activité concentrée à des heures spécifiques,\n",
    "\n",
    "- d’autres zones présentent une demande très faible ou occasionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee6f20c-3dcf-4401-93ae-e76ef21f559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfClean = [id: string, vendor_id: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après filtrage des outliers: 1441100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 18 more fields]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filtrer les courses avec distance nulle ou trop grande et vitesse improbable\n",
    "val dfClean = dfSpeed\n",
    "  .filter($\"distance_km\" > 0.01 && $\"distance_km\" < 500)  // distance plausible\n",
    "  .filter($\"speed_kmph\" > 0.5 && $\"speed_kmph\" < 160)     // vitesse réaliste\n",
    "\n",
    "println(s\"Nombre de lignes après filtrage des outliers: ${dfClean.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdd863-6c00-4109-a236-97e8c9e754f9",
   "metadata": {},
   "source": [
    "**Interprétation – Filtrage des outliers**:\n",
    "\n",
    "Ce code nettoie les données en supprimant les courses non réalistes :\n",
    "\n",
    "- distances nulles ou excessives,\n",
    "\n",
    "- vitesses trop faibles ou trop élevées.\n",
    "\n",
    "Après ce filtrage, 1 441 100 courses sont conservées, ce qui garantit une base de données fiable et cohérente pour l’analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4d4fe2-6218-4334-8a0a-f23a31b8eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+-----------------+------------------+------------------+-----------------+\n",
      "|mean_trip_s      |median_trip_s|std_trip_s       |mean_km           |median_km         |std_km           |\n",
      "+-----------------+-------------+-----------------+------------------+------------------+-----------------+\n",
      "|849.9836048851572|665          |1030.919862183811|3.4733188891949354|2.1168295052175594|3.960717922716133|\n",
      "+-----------------+-------------+-----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Statistiques descriptives\n",
    "// Moyenne, médiane et écart type\n",
    "dfClean.select(\n",
    "  mean(\"trip_duration\").alias(\"mean_trip_s\"),\n",
    "  expr(\"percentile_approx(trip_duration, 0.5)\").alias(\"median_trip_s\"),\n",
    "  stddev(\"trip_duration\").alias(\"std_trip_s\"),\n",
    "  mean(\"distance_km\").alias(\"mean_km\"),\n",
    "  expr(\"percentile_approx(distance_km, 0.5)\").alias(\"median_km\"),\n",
    "  stddev(\"distance_km\").alias(\"std_km\")\n",
    ").show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545733fd-f976-449c-b14f-902a0c41268b",
   "metadata": {},
   "source": [
    "**Interprétation – Statistiques descriptives**:\n",
    "\n",
    "Les statistiques montrent que :\n",
    "\n",
    "- la durée moyenne d’un trajet est d’environ 850 secondes (~14 min), avec une médiane plus faible (665 s), indiquant une distribution asymétrique avec quelques trajets très longs.\n",
    "\n",
    "- la distance moyenne est de 3,47 km, alors que la médiane est d’environ 2,12 km, ce qui confirme que la majorité des trajets sont courts.\n",
    "\n",
    "- les écarts types élevés révèlent une forte variabilité des trajets, typique d’un contexte urbain comme New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0806d87f-4c65-49b5-b524-04d62ddb83e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|count|\n",
      "+--------------------+-----+\n",
      "|40.752,-73.978->4...|  107|\n",
      "|40.774,-73.873->4...|   92|\n",
      "|40.762,-73.979->4...|   83|\n",
      "|40.751,-73.994->4...|   70|\n",
      "|40.774,-73.873->4...|   66|\n",
      "|40.741,-73.986->4...|   65|\n",
      "|40.763,-73.982->4...|   61|\n",
      "|40.751,-73.994->4...|   60|\n",
      "|40.749,-73.992->4...|   59|\n",
      "|40.752,-73.977->4...|   57|\n",
      "|40.77,-73.864->40...|   56|\n",
      "|40.764,-73.981->4...|   56|\n",
      "|40.774,-73.871->4...|   55|\n",
      "|40.752,-73.978->4...|   55|\n",
      "|40.738,-73.988->4...|   55|\n",
      "|40.737,-73.989->4...|   54|\n",
      "|40.751,-73.994->4...|   52|\n",
      "|40.742,-74.001->4...|   50|\n",
      "|40.769,-73.863->4...|   50|\n",
      "|40.75,-73.992->40...|   50|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfRoutes = [id: string, vendor_id: int ... 21 more fields]\n",
       "topRoutes = [route: string, count: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[route: string, count: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Routes fréquentes\n",
    "val dfRoutes = dfClean\n",
    "  .withColumn(\"pickup_pair\", concat_ws(\",\", round($\"pickup_latitude\",3), round($\"pickup_longitude\",3)))\n",
    "  .withColumn(\"dropoff_pair\", concat_ws(\",\", round($\"dropoff_latitude\",3), round($\"dropoff_longitude\",3)))\n",
    "  .withColumn(\"route\", concat_ws(\"->\", $\"pickup_pair\", $\"dropoff_pair\"))\n",
    "\n",
    "val topRoutes = dfRoutes.groupBy(\"route\").count().orderBy(desc(\"count\"))\n",
    "topRoutes.show(20)\n",
    "topRoutes.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/top_routes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f1360-8844-4635-adf1-8b2adb3af88a",
   "metadata": {},
   "source": [
    "**Interprétation – Routes fréquentes**:\n",
    "\n",
    "Ce code identifie les trajets les plus fréquents en regroupant les points de départ et d’arrivée après arrondi des coordonnées GPS à 3 décimales, ce qui permet de définir des zones approximatives plutôt que des points exacts.\n",
    "\n",
    "Les résultats montrent que :\n",
    "\n",
    "- certaines routes sont répétées très souvent, avec plus de 100 trajets identiques,\n",
    "\n",
    "- ces routes correspondent majoritairement à des zones centrales et stratégiques (gares, centres d’affaires, aéroports)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a7c76-44aa-4c31-9d5f-5aaccbc4ff32",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "La répétition de ces trajets indique l’existence de corridors de mobilité très utilisés, reflétant des déplacements réguliers entre des zones clés de la ville."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0cc5522-329f-4fa8-90ab-62e80a7ca2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfForML = [pickup_ts: timestamp, dropoff_ts: timestamp ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[pickup_ts: timestamp, dropoff_ts: timestamp ... 9 more fields]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Export final dataset nettoyé pour ML\n",
    "val dfForML = dfClean.select(\n",
    "  $\"pickup_ts\", $\"dropoff_ts\", $\"pickup_hour\", $\"pickup_dayofweek\", $\"pickup_month\", $\"pickup_weekday\",\n",
    "  $\"passenger_count\", $\"distance_km\", $\"trip_duration\", $\"trip_min\", $\"speed_kmph\"\n",
    ")\n",
    "\n",
    "dfForML.write.mode(\"overwrite\").parquet(\"outputs/nyc_taxi_clean.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbff8c7-e29e-4d82-96d6-01d259d07c0b",
   "metadata": {},
   "source": [
    "**Export du dataset nettoyé pour ML**\n",
    "\n",
    "Le code sélectionne les colonnes les plus pertinentes pour l’apprentissage machine (pickup_ts, dropoff_ts, pickup_hour, distance_km, trip_duration, etc.) et les exporte au format Parquet.\n",
    "\n",
    "- Cela permet de créer un dataset propre et optimisé pour les modèles prédictifs (par exemple prédiction de la durée des trajets).\n",
    "\n",
    "- Parquet est choisi pour sa compression et son efficacité de lecture avec Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f812da7a-9d7c-4689-8426-aac2e1ca0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies distance: 143542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q1Dist = 1.239383570220805\n",
       "q3Dist = 3.830537219099838\n",
       "iqrDist = 2.591153648879033\n",
       "anomaliesDist = [id: string, vendor_id: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 18 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// détection d’anomalies simples\n",
    "// IQR-based anomalies pour distance et durée\n",
    "val Array(q1Dist, q3Dist) = dfClean.stat.approxQuantile(\"distance_km\", Array(0.25,0.75), 0.01)\n",
    "val iqrDist = q3Dist - q1Dist\n",
    "val anomaliesDist = dfClean.filter($\"distance_km\" < q1Dist - 1.5*iqrDist || $\"distance_km\" > q3Dist + 1.5*iqrDist)\n",
    "println(s\"Anomalies distance: ${anomaliesDist.count()}\")\n",
    "anomaliesDist.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/anomalies_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae634a5-8846-48ae-9e19-62cc734cfd94",
   "metadata": {},
   "source": [
    "**Détection d’anomalies simples (IQR)**\n",
    "\n",
    "- On calcule l’IQR (interquartile range) sur la distance pour détecter les trajets aberrants : trop courts ou trop longs.\n",
    "\n",
    "- Exemple : environ 143 542 courses sont considérées comme anomalies sur 1 441 100 trajets.\n",
    "\n",
    "- Ces anomalies peuvent être exclues ou étudiées séparément pour améliorer la qualité du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484f6f98-e580-4af0-9e2a-a7bf1cdb9581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation distance_km ↔ trip_duration : 0.5212754973100158\n",
      "Corrélation speed_kmph ↔ trip_duration : 0.025787056868200084\n",
      "+-----------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "|pickup_hour|                1|                 2|                 3|                 4|                 5|                6|\n",
      "+-----------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "|          0|779.2117226550502| 808.2224009190121|  791.550042408821| 813.2803738317757| 856.6091875214262|765.4053880692752|\n",
      "|          1|748.7430871139182| 766.0483682008369| 756.9690831556503| 724.2337209302326| 780.6540307101727|818.7862776025237|\n",
      "|          2|727.1558289396602| 730.6873853211009|  718.659511472983| 731.0361445783133| 697.9954188481676|725.6741176470588|\n",
      "|          3|724.9454843071668| 726.9565082323703| 734.9909547738694|  938.751708428246| 712.8064798598949|710.4676258992806|\n",
      "|          4|747.2202447163515| 790.3458507185907| 751.0583941605839| 827.5380116959064| 842.2587176602925|740.1978798586572|\n",
      "|          5|743.4124820659971|  833.412865497076| 831.6085106382978|  860.421052631579| 742.7776073619632|735.6029411764706|\n",
      "|          6|667.9213286031734| 797.3810096153846| 756.0060606060606| 760.6447058823529| 698.5741721854305|659.9044943820224|\n",
      "|          7|761.9585287465778| 827.2242040340057| 812.1622125543817| 833.3568345323741| 756.0594673476834|770.5118025751073|\n",
      "|          8|831.0158205004813| 869.5237204329815| 865.6395891690009|1009.0050916496945| 870.5315107913669|853.7507520412548|\n",
      "|          9| 841.163178913738| 887.9490722463482| 894.4146228597872| 883.8449691991786| 881.0207100591716|821.1566514711977|\n",
      "|         10|844.6325474898237| 898.9288795759892| 908.9737954353338| 1024.981981981982| 848.7142056598487| 841.889816360601|\n",
      "|         11|870.5834601933758| 941.9448420125509| 925.8960988798764| 921.9313962873285| 903.8813286900617|865.6688605512135|\n",
      "|         12|872.7890436910448| 943.2836489513337| 968.4946124435176| 934.3658724058416| 913.5805606497249|890.3473767885532|\n",
      "|         13| 894.150388867785| 981.9012407444467| 924.1494174091844|1026.2683578104138|  953.044065963774|913.1220190779014|\n",
      "|         14|935.3931729783076| 1028.140654559213|1035.6499835363845|1107.6613226452905| 977.2648030495553| 934.688654353562|\n",
      "|         15|964.7757613474395|1039.5483257229832|1035.4712755598832|1068.8693759071118|1030.5630026809652|925.5423445974135|\n",
      "|         16|975.9336694323243|1052.2351546391753|1015.4597660404112|1094.2441064638783| 944.5249311716121| 982.903738317757|\n",
      "|         17|927.1867795902091| 996.1778813559322| 962.1480272916049|1001.5862068965517|            938.05|977.4719245606515|\n",
      "|         18|859.8886931403358| 927.8899446356427| 902.0720580611716| 911.9723632261704| 885.2752217866722|898.4976559682655|\n",
      "|         19|789.3213828834591|  824.021007173181|  818.430343758077| 837.6578366445916| 817.4788971367974| 789.268371757925|\n",
      "|         20|772.4342010122921| 792.0535980538335| 786.1902718168812| 793.9593679458239| 795.2382829610162|777.9808518952716|\n",
      "|         21| 781.142737180945| 800.0371666914941| 829.9610110244689|  805.525309336333| 808.3794156127344|776.1850699844479|\n",
      "|         22|811.0582356867399| 821.0300836070469| 810.4990408331049| 812.4692861095739| 837.4785055142921|877.4701902748415|\n",
      "|         23|815.1119766724134| 845.7404701118056| 821.6865907653383| 837.9340519974635|    862.7119550682|829.9539906103287|\n",
      "+-----------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pivotHourPassenger = [pickup_hour: int, 1: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[pickup_hour: int, 1: double ... 5 more fields]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Corrélations et pivot tables pour ML\n",
    "//Corrélation distance ↔ durée, vitesse ↔ durée.\n",
    "//Pivot pickup_hour x passenger_count pour features additionnelles\n",
    "println(s\"Corrélation distance_km ↔ trip_duration : ${dfClean.stat.corr(\"distance_km\",\"trip_duration\")}\")\n",
    "println(s\"Corrélation speed_kmph ↔ trip_duration : ${dfClean.stat.corr(\"speed_kmph\",\"trip_duration\")}\")\n",
    "\n",
    "val pivotHourPassenger = dfClean.groupBy(\"pickup_hour\").pivot(\"passenger_count\").agg(avg(\"trip_duration\")).orderBy(\"pickup_hour\")\n",
    "pivotHourPassenger.show(24)\n",
    "pivotHourPassenger.coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"outputs/pivot_hour_passenger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c113f34-7e1e-48fb-96e6-3a81b134413f",
   "metadata": {},
   "source": [
    "**Corrélations et pivot tables**\n",
    "\n",
    "**1.Corrélations :**\n",
    "\n",
    "- distance_km ↔ trip_duration = 0.52 → la durée augmente logiquement avec la distance.\n",
    "\n",
    "- speed_kmph ↔ trip_duration ≈ 0.03 → la vitesse n’influence presque pas directement la durée totale.\n",
    "\n",
    "**2.Pivot Hour x Passenger Count :**\n",
    "\n",
    "- Création d’un tableau où chaque ligne = heure de prise en charge, chaque colonne = nombre de passagers, et chaque cellule = durée moyenne du trajet.\n",
    "\n",
    "- Utile pour créer des features additionnelles dans les modèles ML, par exemple pour capturer l’effet du nombre de passagers sur la durée selon l’heure de la journée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bb19d-096c-44fc-ae20-f5ad41b8386e",
   "metadata": {},
   "source": [
    "**Insight général**\n",
    "\n",
    "- Le dataset final est prêt pour ML, avec nettoyage des outliers, features temporelles, anomalies identifiées, et structuration en pivot tables pour enrichir les modèles.\n",
    "\n",
    "- Cela permet d’avoir une vision complète des trajets, incluant leur distribution, anomalies et facteurs influençant la durée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b61e533-6fc2-4735-81c2-ea49381e45ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-------+\n",
      "|pickup_lat_bin_0_01|pickup_lon_bin_0_01|  0|  1|  2|  3|  4|  5|  6|  7|  8|  9| 10| 11| 12| 13| 14| 15| 16| 17| 18| 19| 20| 21| 22| 23|cluster|\n",
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-------+\n",
      "|              40.65|             -73.96| 14| 10|  6|  4|  8|  5|  7|  8|  2|  2|  5|  0|  1|  1|  0|  2|  1|  3|  2|  0|  3|  4|  5| 10|      0|\n",
      "|              40.81|             -73.99|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|      0|\n",
      "|              40.59|             -73.95|  0|  0|  0|  0|  2|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|      0|\n",
      "|              40.68|             -73.82|  1|  1|  0|  0|  0|  0|  0|  1|  2|  2|  1|  0|  1|  0|  0|  0|  0|  1|  2|  0|  0|  3|  2|  3|      0|\n",
      "|              40.81|             -74.08|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|      0|\n",
      "|              40.76|             -73.88|  8| 10| 15| 12| 19| 14| 33| 15| 14|  7|  5|  4|  7|  8|  9|  6|  5|  4|  5|  5|  4|  4|  3|  6|      0|\n",
      "|              40.57|             -73.84|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|      0|\n",
      "|              40.85|             -73.88|  0|  0|  0|  0|  0|  0|  0|  1|  0|  1|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  0|  0|      0|\n",
      "|              40.84|             -73.78|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|      0|\n",
      "|               41.0|             -73.68|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|      0|\n",
      "+-------------------+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hourCols = Array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23)\n",
       "assembler = VectorAssembler: uid=vecAssembler_d248185184dd, handleInvalid=error, numInputCols=24\n",
       "pivotZoneFeatures = [pickup_lat_bin_0_01: double, pickup_lon_bin_0_01: double ... 25 more fields]\n",
       "kmeans = kmeans_43879e8b6a0a\n",
       "kModel = KMeansModel: uid=kmeans_43879e8b6a0a, k=5, distanceMeasure=euclidean, numFeatures=24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "dfClustered: org.apache....\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "KMeansModel: uid=kmeans_43879e8b6a0a, k=5, distanceMeasure=euclidean, numFeatures=24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Clustering : zones de forte demande par heure\n",
    "import org.apache.spark.ml.clustering.KMeans\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Créer le vecteur de features (colonnes d'heures 0..23)\n",
    "val hourCols = (0 to 23).map(_.toString).toArray\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(hourCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val pivotZoneFeatures = assembler.transform(pivotZone)\n",
    "\n",
    "// Appliquer KMeans\n",
    "val kmeans = new KMeans()\n",
    "  .setK(5)\n",
    "  .setSeed(42)\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setPredictionCol(\"cluster\")\n",
    "\n",
    "val kModel = kmeans.fit(pivotZoneFeatures)\n",
    "\n",
    "// Ajouter la colonne cluster\n",
    "val dfClustered = kModel.transform(pivotZoneFeatures)\n",
    "\n",
    "// Supprimer la colonne 'features' avant l'export CSV\n",
    "val dfToSave = dfClustered.drop(\"features\")\n",
    "\n",
    "// Export CSV\n",
    "dfToSave.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(\"outputs/zone_clusters\")\n",
    "\n",
    "// Vérification\n",
    "dfToSave.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62316a81-8384-4a78-a9a0-bdc84aac24af",
   "metadata": {},
   "source": [
    "**Interprétation des résultats :**\n",
    "\n",
    "- Chaque ligne correspond à une zone (latitude/longitude arrondie) avec :\n",
    "\n",
    "    - Les nombre de courses par heure (0 → 23)\n",
    "\n",
    "    - Le cluster auquel appartient la zone\n",
    "\n",
    "- Les clusters permettent d’identifier :\n",
    "\n",
    "    - Zones très actives toute la journée\n",
    "\n",
    "    - Zones actives seulement aux heures de pointe\n",
    "\n",
    "    - Zones peu fréquentées\n",
    "\n",
    "Cela aide à la planification opérationnelle, comme l’affectation des taxis ou la prédiction de demande par quartier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d08086f-b828-4358-9eaf-f28a06c21ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer = strIdx_0606206c8f83\n",
       "numericCols = Array(passenger_count, distance_km, pickup_hour, pickup_weekday, pickup_month)\n",
       "assemblerML = VectorAssembler: uid=vecAssembler_c62d2abf344b, handleInvalid=error, numInputCols=6\n",
       "scaler = stdScal_7a31efb8a683\n",
       "trainData = [id: string, vendor_id: int ... 18 more fields]\n",
       "testData = [id: string, vendor_id: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 18 more fields]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Préparation ML : train/test split, encodage, scaling\n",
    "//Pour prédire trip_duration :\n",
    "import org.apache.spark.ml.feature.{StringIndexer, VectorAssembler, StandardScaler}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "// Encodage de store_and_fwd_flag\n",
    "val indexer = new StringIndexer()\n",
    "  .setInputCol(\"store_and_fwd_flag\")\n",
    "  .setOutputCol(\"store_and_fwd_flag_idx\")\n",
    "\n",
    "// Sélection des features numériques\n",
    "val numericCols = Array(\"passenger_count\",\"distance_km\",\"pickup_hour\",\"pickup_weekday\",\"pickup_month\")\n",
    "\n",
    "// Assemblage en un vecteur de features\n",
    "val assemblerML = new VectorAssembler()\n",
    "  .setInputCols(numericCols ++ Array(\"store_and_fwd_flag_idx\"))\n",
    "  .setOutputCol(\"features_raw\")\n",
    "\n",
    "// Scaling\n",
    "val scaler = new StandardScaler()\n",
    "  .setInputCol(\"features_raw\")\n",
    "  .setOutputCol(\"features\")\n",
    "  .setWithStd(true)\n",
    "  .setWithMean(true)\n",
    "\n",
    "// Split train/test\n",
    "val Array(trainData, testData) = dfClean.randomSplit(Array(0.8,0.2), seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadcbde-0a96-4868-8afe-a076d7211575",
   "metadata": {},
   "source": [
    "Le code décrit la préparation des données pour un modèle de machine learning visant à prédire la durée des courses (trip_duration). Les étapes réalisées sont les suivantes :\n",
    "\n",
    "**1.Encodage des variables catégorielles :**\n",
    "La colonne contenant des indicateurs textuels (comme \"Y\" ou \"N\") est transformée en valeurs numériques pour que le modèle puisse les utiliser.\n",
    "\n",
    "**2.Sélection des caractéristiques pertinentes :**\n",
    "Les colonnes choisies incluent le nombre de passagers, la distance du trajet, l’heure et le jour de la prise en charge, ainsi que le mois. Ce sont les informations jugées utiles pour prédire la durée de course.\n",
    "\n",
    "**3.Assemblage des features :**\n",
    "Toutes les caractéristiques numériques et encodées sont combinées en un seul vecteur, ce qui est le format attendu par les algorithmes de machine learning.\n",
    "\n",
    "**4.Normalisation des données :**\n",
    "Les valeurs sont standardisées afin que toutes les caractéristiques aient la même échelle. Cela améliore la performance et la stabilité des modèles.\n",
    "\n",
    "**5.Séparation du dataset :**\n",
    "Les données sont divisées en deux parties : 80 % pour l’entraînement du modèle et 20 % pour tester sa performance. Cette séparation permet d’évaluer la capacité du modèle à généraliser sur de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e218a-e971-4573-b0a1-b00d3bc2d199",
   "metadata": {},
   "source": [
    "***Pipeline ML Spark : RandomForest / GBT / XGBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ea75794-cd64-4612-a092-9e39012e8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|trip_duration|       prediction|\n",
      "+-------------+-----------------+\n",
      "|         1134|825.9041195825154|\n",
      "|          592|560.0089441817593|\n",
      "|         1677|886.2195063509994|\n",
      "|          303|612.2211725289917|\n",
      "|          189|530.1144007151372|\n",
      "|          233| 554.217722021075|\n",
      "|          998|826.8834488134926|\n",
      "|           95|634.3060539801587|\n",
      "|         1041|889.1332625294153|\n",
      "|          500|608.1625194360639|\n",
      "+-------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE RandomForest: 895.9559161395179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rf = rfr_2463b3c1c53e\n",
       "pipelineRF = pipeline_48cababd3e18\n",
       "modelRF = pipeline_48cababd3e18\n",
       "predictionsRF = [id: string, vendor_id: int ... 22 more fields]\n",
       "evaluator = RegressionEvaluator: uid=regEval_ce83b124e4fe, metricName=rmse, throughOrigin=false\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "RegressionEvaluator: uid=regEval_ce83b124e4fe, metricName=rmse, throughOrigin=false"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// RandomForest\n",
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "val rf = new RandomForestRegressor()\n",
    "  .setLabelCol(\"trip_duration\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setNumTrees(100)\n",
    "\n",
    "val pipelineRF = new Pipeline().setStages(Array(indexer, assemblerML, scaler, rf))\n",
    "\n",
    "val modelRF = pipelineRF.fit(trainData)\n",
    "val predictionsRF = modelRF.transform(testData)\n",
    "\n",
    "predictionsRF.select(\"trip_duration\",\"prediction\").show(10)\n",
    "\n",
    "// Évaluation\n",
    "val evaluator = new RegressionEvaluator()\n",
    "  .setLabelCol(\"trip_duration\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "println(s\"RMSE RandomForest: ${evaluator.evaluate(predictionsRF)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb001b-d339-468d-8070-5ddff95d236d",
   "metadata": {},
   "source": [
    "**Interpretations:**\n",
    "\n",
    "**1.Comparaison prédictions vs valeurs réelles :**\n",
    "\n",
    "- Par exemple, une course réelle de 1134 secondes a été prédite à 826 secondes, une autre de 592 secondes à 560 secondes, etc.\n",
    "\n",
    "- On remarque que pour des courses courtes, la prédiction est relativement proche, tandis que pour des courses très longues, le modèle sous-estime souvent la durée.\n",
    "\n",
    "**2. RMSE = 895,96 secondes :**\n",
    "\n",
    "- Le Root Mean Squared Error indique qu’en moyenne, les prédictions du modèle diffèrent des valeurs réelles d’environ 896 secondes (~15 minutes).\n",
    "\n",
    "- Cela montre que le modèle capture les tendances globales mais qu’il a encore une marge d’erreur notable, surtout pour les courses très longues ou très courtes.\n",
    "\n",
    "**3.Tendance générale :**\n",
    "\n",
    "- La Random Forest fonctionne mieux pour les durées “typical” ou moyennes, mais les valeurs extrêmes (courses très courtes ou très longues) sont moins bien prédites.\n",
    "\n",
    "- Cela peut être dû à la distribution très dispersée des durées et à la présence de valeurs atypiques même après nettoyage.\n",
    "\n",
    "\n",
    "En résumé : le modèle est utile pour avoir une estimation générale de la durée d’une course, mais il n’est pas extrêmement précis pour toutes les courses, surtout celles aux extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b680589-a1fb-40be-9da9-8a638b7f4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE GBT: 867.5099355083967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gbt = gbtr_90dfecbc237b\n",
       "pipelineGBT = pipeline_e0920f277056\n",
       "modelGBT = pipeline_e0920f277056\n",
       "predictionsGBT = [id: string, vendor_id: int ... 22 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 22 more fields]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Gradient Boosted Trees (GBT) \n",
    "import org.apache.spark.ml.regression.GBTRegressor \n",
    "val gbt = new GBTRegressor()\n",
    "  .setLabelCol(\"trip_duration\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setMaxIter(100)\n",
    "val pipelineGBT = new Pipeline().setStages(Array(indexer, assemblerML, scaler, gbt)) \n",
    "val modelGBT = pipelineGBT.fit(trainData) \n",
    "val predictionsGBT = modelGBT.transform(testData) \n",
    "println(s\"RMSE GBT: ${evaluator.evaluate(predictionsGBT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c064f7-6df4-40c1-999c-b460e2420cff",
   "metadata": {},
   "source": [
    "**Interpretations :**\n",
    "**1. RMSE = 867,51 secondes :**\n",
    "\n",
    "- Le modèle a une erreur quadratique moyenne d’environ 867 secondes (~14,5 minutes).\n",
    "\n",
    "- Comparé au Random Forest (RMSE ≈ 896 s), le GBT réduit légèrement l’erreur, ce qui indique qu’il est un peu plus précis pour prédire la durée des courses.\n",
    "\n",
    "**2. Performance globale :**\n",
    "\n",
    "- Comme pour Random Forest, le modèle capture globalement les tendances des durées de courses.\n",
    "\n",
    "- Les courses très longues ou très courtes restent difficiles à prédire avec précision, mais le GBT gère mieux certaines valeurs extrêmes grâce à son apprentissage itératif et pondéré.\n",
    "\n",
    "**3.Tendance :**\n",
    "\n",
    "- Les prédictions GBT sont généralement plus proches des valeurs réelles, surtout pour les courses dont la durée est proche de la moyenne.\n",
    "\n",
    "- Les valeurs atypiques continuent de poser un défi, mais GBT est plus robuste aux variations que RF.\n",
    "\n",
    "\n",
    "En résumé :\n",
    "\n",
    "- Le GBT est légèrement plus performant que Random Forest pour ce jeu de données.\n",
    "\n",
    "- Il reste utile pour une estimation générale des durées de courses, mais des erreurs importantes peuvent subsister sur les courses extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4abba353-ecd8-448c-a7d1-eca9084e0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Random Forest: 895.9559161395179\n",
      "RMSE GBT: 867.5099355083967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "evaluator = RegressionEvaluator: uid=regEval_1c49ce59d7e3, metricName=rmse, throughOrigin=false\n",
       "rmseRF = 895.9559161395179\n",
       "rmseGBT = 867.5099355083967\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "867.5099355083967"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new RegressionEvaluator()\n",
    "  .setLabelCol(\"trip_duration\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"rmse\") // Root Mean Squared Error\n",
    "\n",
    "val rmseRF = evaluator.evaluate(predictionsRF)\n",
    "val rmseGBT = evaluator.evaluate(predictionsGBT)\n",
    "\n",
    "println(s\"RMSE Random Forest: $rmseRF\")\n",
    "println(s\"RMSE GBT: $rmseGBT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673f2174-23d5-4d3c-9f99-04f1b9eb930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Le meilleur modèle est GBT\n",
      "+-------------+------------------+------------------+------------------+\n",
      "|trip_duration|        prediction|   pickup_latitude|  pickup_longitude|\n",
      "+-------------+------------------+------------------+------------------+\n",
      "|         1134| 978.3795778974707|40.788631439208984|-73.97711944580078|\n",
      "|          592| 554.3954429566435|40.751060485839844| -73.9736099243164|\n",
      "|         1677| 1247.921261791818| 40.76898956298828|-73.96556091308594|\n",
      "|          303|291.55011892555086| 40.77553939819336|-73.95832824707031|\n",
      "|          189| 365.6458398644942|40.733150482177734|-73.98651123046875|\n",
      "|          233| 279.0284082563539|40.748809814453125|-73.97776794433594|\n",
      "|          998| 945.1849443711409| 40.75951385498047|-73.97789001464844|\n",
      "|           95| 328.1358937808762| 40.79323959350586|-73.96708679199219|\n",
      "|         1041|1178.7157384035297|40.815181732177734|-73.95893859863281|\n",
      "|          500| 601.8732965340262| 40.76447296142578|-73.96620178222656|\n",
      "+-------------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bestModel = pipeline_e0920f277056\n",
       "finalPredictions = [id: string, vendor_id: int ... 22 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[id: string, vendor_id: int ... 22 more fields]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Choix du meilleur modèle\n",
    "val bestModel = if (rmseRF < rmseGBT) {\n",
    "  println(\"➡️ Le meilleur modèle est Random Forest\")\n",
    "  modelRF\n",
    "} else {\n",
    "  println(\"➡️ Le meilleur modèle est GBT\")\n",
    "  modelGBT\n",
    "}\n",
    "\n",
    "// Test final sur de nouvelles données\n",
    "val finalPredictions = bestModel.transform(testData)\n",
    "finalPredictions.select(\"trip_duration\", \"prediction\", \"pickup_latitude\", \"pickup_longitude\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448711ec-365e-41e3-88dc-d9c055b5e12f",
   "metadata": {},
   "source": [
    "**interprétations:**\n",
    "\n",
    "**1.Sélection du meilleur modèle :**\n",
    "\n",
    "- Après comparaison des RMSE entre Random Forest (≈896 s) et GBT (≈868 s), le GBT a été retenu comme le meilleur modèle, car il prédit la durée des courses avec une erreur légèrement plus faible.\n",
    "\n",
    "- Cela montre que l’apprentissage itératif et pondéré du GBT capture mieux les variations dans les données que le Random Forest classique.\n",
    "\n",
    "**2.Prédictions finales :**\n",
    "\n",
    "Les prédictions du modèle GBT sur le jeu de test montrent que :\n",
    "\n",
    "- Pour certaines courses longues (ex. 1677 s), le modèle sous-estime légèrement (prédit 1248 s).\n",
    "\n",
    "- Pour des courses courtes (ex. 303 s), le modèle est assez précis (prédit 292 s).\n",
    "\n",
    "- La plupart des prédictions sont proches des valeurs réelles, surtout pour les durées autour de la moyenne.\n",
    "\n",
    "- Les colonnes pickup_latitude et pickup_longitude permettent éventuellement d’analyser la performance du modèle selon la zone géographique.\n",
    "\n",
    "**3.Conclusion générale :**\n",
    "\n",
    "- Le GBT est le modèle final recommandé pour prédire la durée des courses de taxi à New York sur ce jeu de données.\n",
    "\n",
    "- Les prédictions sont raisonnablement précises pour la majorité des courses, mais certaines valeurs extrêmes restent difficiles à estimer avec exactitude.\n",
    "\n",
    "- Le modèle peut être utilisé pour la planification, l’optimisation des trajets ou l’analyse de la demande par zone et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632ea1f-b85f-43c2-94da-0a244303a8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark Scala - Scala",
   "language": "scala",
   "name": "spark_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
